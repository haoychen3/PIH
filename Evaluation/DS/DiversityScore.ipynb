{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f61c0be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "795bf012",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "with open('image_id.csv', 'w', newline='') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerow(['image_id'])\n",
    "    for filename in os.listdir(\"gen_samples\"):\n",
    "        data.append(filename)\n",
    "        writer.writerow(data)\n",
    "        data=[]\n",
    "writeFile.close()\n",
    "\n",
    "df = pd.read_csv('image_id.csv')\n",
    "\n",
    "\n",
    "class LeafData(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 directory,\n",
    "                 transform=None):\n",
    "        self.data = data\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # import\n",
    "        path = os.path.join(self.directory, self.data.iloc[idx]['image_id'])\n",
    "        image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # augmentations\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)['image']\n",
    "\n",
    "        return image\n",
    "\n",
    "# dataset\n",
    "image_dataset = LeafData(data      = df,\n",
    "                         directory = 'gen_samples',\n",
    "                         transform = None)\n",
    "\n",
    "# data loader\n",
    "image_loader = DataLoader(image_dataset,\n",
    "                          batch_size  = 1,\n",
    "                          shuffle     = False,\n",
    "                          num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e211cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 469.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "path1 = pathlib.Path('./Image-coco/cover/')\n",
    "files1 = list(path1.glob('*'))\n",
    "\n",
    "train_image_list = []\n",
    "\n",
    "for i in range(len(files1)):\n",
    "\n",
    "    # read training image\n",
    "    train_image = cv2.imread(str(files1[i]), cv2.IMREAD_COLOR)\n",
    "    train_image = torch.from_numpy(train_image).to(torch.long)\n",
    "    \n",
    "    # append to lists\n",
    "    train_image_list.append(train_image)\n",
    "    \n",
    "\n",
    "# placeholders\n",
    "psum    = torch.zeros_like(train_image)\n",
    "psum_sq = torch.zeros_like(train_image)\n",
    "\n",
    "i = 0\n",
    "psum_list = []\n",
    "psum_sq_list = []\n",
    "\n",
    "# loop through 1000 sampled images\n",
    "for inputs in tqdm(image_loader):\n",
    "    inputs = inputs.to(torch.long)\n",
    "    # print(inputs.size())\n",
    "    psum    += inputs.sum(axis        = [0])\n",
    "    psum_sq += (inputs ** 2).sum(axis = [0])\n",
    "    i += 1\n",
    "    if i % 25==0:\n",
    "        psum_list.append(psum)\n",
    "        psum_sq_list.append(psum_sq)\n",
    "        psum    = torch.zeros_like(train_image)\n",
    "        psum_sq = torch.zeros_like(train_image)\n",
    "\n",
    "print(len(psum_list))\n",
    "print(len(psum_sq_list))\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b07f838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(27.1471), tensor(21.7544), tensor(14.0521), tensor(17.5488), tensor(22.9270), tensor(29.5459), tensor(18.3266), tensor(14.9391), tensor(28.6792), tensor(18.9467), tensor(16.9008), tensor(28.1648), tensor(30.9998), tensor(15.9014), tensor(16.8295), tensor(26.1731), tensor(14.3156), tensor(16.2218), tensor(21.4377), tensor(11.8613), tensor(29.7708), tensor(16.6423), tensor(36.0550), tensor(18.8303), tensor(16.7913), tensor(22.5471), tensor(17.6061), tensor(16.1859), tensor(14.6325), tensor(22.2143), tensor(15.6117), tensor(16.1569), tensor(15.4818), tensor(13.9603), tensor(14.7105), tensor(28.0563), tensor(8.4409), tensor(13.1589), tensor(18.7084), tensor(22.7228)]\n"
     ]
    }
   ],
   "source": [
    "# image_size\n",
    "count = 244 * 164\n",
    "\n",
    "std_list = []\n",
    "\n",
    "####### Calculate the Standard Deviation of each set of generated cover images\n",
    "for i in range(len(psum_list)):\n",
    "    mean = psum_list[i] / 25\n",
    "    var = psum_sq_list[i] / 25 - (mean ** 2)\n",
    "    std = torch.sqrt(var.sum(axis=[0, 1]) / count)\n",
    "    # print('average pixel-wise std for each channel:  '  + str(std))\n",
    "    std = torch.mean(std)\n",
    "    # print('average std:  '  + str(std))\n",
    "    \n",
    "    std_list.append(std)\n",
    "    \n",
    "print(std_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e540cf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(63.7685), tensor(40.8997), tensor(37.1177), tensor(50.4098), tensor(66.1276), tensor(36.5928), tensor(25.2818), tensor(32.0097), tensor(63.8315), tensor(56.9703), tensor(21.2125), tensor(49.6604), tensor(50.9792), tensor(16.5515), tensor(54.1654), tensor(44.8908), tensor(38.4053), tensor(46.9346), tensor(38.9547), tensor(33.5067), tensor(47.8889), tensor(24.9307), tensor(44.2016), tensor(32.5984), tensor(40.3982), tensor(57.5092), tensor(35.2511), tensor(24.8039), tensor(54.9696), tensor(45.1007), tensor(44.5546), tensor(43.7827), tensor(31.5404), tensor(33.5104), tensor(25.2575), tensor(43.9963), tensor(35.9467), tensor(70.8452), tensor(32.2612), tensor(73.6799)]\n"
     ]
    }
   ],
   "source": [
    "####### Calculate the Standard Deviation of each Traning Image\n",
    "train_std_list = []\n",
    "\n",
    "for i in range(len(train_image_list)):\n",
    "    psum    = torch.tensor([0.0,0.0,0.0])\n",
    "    psum_sq = torch.tensor([0.0,0.0,0.0])\n",
    "    \n",
    "    psum    += train_image_list[i].sum(axis        = [0, 1])\n",
    "    psum_sq += (train_image_list[i] ** 2).sum(axis = [0, 1])\n",
    "    \n",
    "    # mean and std of i-th training image\n",
    "    train_mean = psum / count\n",
    "    train_var  = (psum_sq / count) - (train_mean ** 2)\n",
    "    train_std  = torch.sqrt(train_var)\n",
    "    # print('pixel-wise average std of training image for each channel:  '  + str(train_std))\n",
    "    train_std = torch.mean(train_std)\n",
    "    # print('average std of training image:  '  + str(train_std))\n",
    "\n",
    "    train_std_list.append(train_std)\n",
    "\n",
    "print(train_std_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d577eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity Score:  tensor(0.4257)\n",
      "Diversity Score:  tensor(0.5319)\n",
      "Diversity Score:  tensor(0.3786)\n",
      "Diversity Score:  tensor(0.3481)\n",
      "Diversity Score:  tensor(0.3467)\n",
      "Diversity Score:  tensor(0.8074)\n",
      "Diversity Score:  tensor(0.7249)\n",
      "Diversity Score:  tensor(0.4667)\n",
      "Diversity Score:  tensor(0.4493)\n",
      "Diversity Score:  tensor(0.3326)\n",
      "Diversity Score:  tensor(0.7967)\n",
      "Diversity Score:  tensor(0.5671)\n",
      "Diversity Score:  tensor(0.6081)\n",
      "Diversity Score:  tensor(0.9607)\n",
      "Diversity Score:  tensor(0.3107)\n",
      "Diversity Score:  tensor(0.5830)\n",
      "Diversity Score:  tensor(0.3727)\n",
      "Diversity Score:  tensor(0.3456)\n",
      "Diversity Score:  tensor(0.5503)\n",
      "Diversity Score:  tensor(0.3540)\n",
      "Diversity Score:  tensor(0.6217)\n",
      "Diversity Score:  tensor(0.6675)\n",
      "Diversity Score:  tensor(0.8157)\n",
      "Diversity Score:  tensor(0.5776)\n",
      "Diversity Score:  tensor(0.4156)\n",
      "Diversity Score:  tensor(0.3921)\n",
      "Diversity Score:  tensor(0.4994)\n",
      "Diversity Score:  tensor(0.6526)\n",
      "Diversity Score:  tensor(0.2662)\n",
      "Diversity Score:  tensor(0.4925)\n",
      "Diversity Score:  tensor(0.3504)\n",
      "Diversity Score:  tensor(0.3690)\n",
      "Diversity Score:  tensor(0.4909)\n",
      "Diversity Score:  tensor(0.4166)\n",
      "Diversity Score:  tensor(0.5824)\n",
      "Diversity Score:  tensor(0.6377)\n",
      "Diversity Score:  tensor(0.2348)\n",
      "Diversity Score:  tensor(0.1857)\n",
      "Diversity Score:  tensor(0.5799)\n",
      "Diversity Score:  tensor(0.3084)\n",
      "Average Diversity Score:  tensor(0.4954)\n"
     ]
    }
   ],
   "source": [
    "####### Normalize to get diversity score\n",
    "div_score_list = []\n",
    "for i in range(len(std_list)):\n",
    "    div_score = std_list[i] / train_std_list[i]\n",
    "    print('Diversity Score:  '  + str(div_score))\n",
    "    div_score_list.append(div_score)\n",
    "\n",
    "print('Average Diversity Score:  '+str(sum(div_score_list)/len(div_score_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce091c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
